# Other Question

## 项目架构介绍

## Mysql

[https://zronghui.github.io/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-MYSQL45%E8%AE%B2-%E7%AC%94%E8%AE%B0.html](https://zronghui.github.io/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-MYSQL45%E8%AE%B2-%E7%AC%94%E8%AE%B0.html)

### 索引怎么优化

合索引的列是出现在where子句中的列，或者连接子句中指定的列； 2）基数较小的类，索引效果较差，没有必要在此列建立索引； 3）使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间； 4）不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可。

前导模糊查询不能命中索引： EXPLAIN SELECT \* FROM user WHERE name LIKE '%s%';

1. InnoDB Buffer size 足够的情况下，即所有数据与索引能完成全加载进内存，查询不会有大问题。如不能会引发内存-硬盘数据交换，看硬盘IO就知道交换频率了。 一般IO在50%以下，性能也不会有大问题。如果 IO到达 100%，整个MySQL不响应的很可能会发生。当然如有其它数据在另一个硬盘，旧连接是不影响的--前提是没有使用swap。当然，带索引的同一语句，也有可能出现非常小量小量的一次慢--原因不明。2. 单表数据过大，维护确实是非常痛苦，alter就别想了；基本上不可能热备，甚至冷备也不可能-- Innodbbackex除外。 3.  大量的sum与count操作 ，即使where条件有索引，对IO也会比小表大1倍。原因不太清楚，曾经有位有装13经验的人跟我说是索引引起IO--- 我想不明白，索引都load到内存了，如何会有IO？一个行数13亿的表，不一定比1亿的表大。还要看表结构。 总体来讲，我认为影响 应该是表+索引 是否能完全装裁到内存。 而当13E行的表分成1024个小表后，这时sum落到是1/1024表中，我理解是单次的IO时间小，并发qps不变的情况下，总IO降了1倍--这个是实际生产环境数据。4.  高IO会引发雪崩，搞不好整个MySQL挂掉。单硬盘安全峰会IO最好在30%以下。

### 一亿条数据查询优化

以主键水平分割表！

如果一年前的只是备份待查,分离出来另存. 如果一年前的会用到,但用得少,用分区. 如果一年前的仍然要频繁使用,用分区,但要加一个磁盘.

### 横向纵向分表

首先存储引擎的使用不同，冷数据使用MyIsam 可以有更好的查询数据。活跃数据，可以使用Innodb,可以有更好的更新速度。 其次，对冷数据进行更多的从库配置，因为更多的操作时查询，这样来加快查询速度。对热数据，可以相对有更多的主库的横向分表处理。 其实，对于一些特殊的活跃数据，也可以考虑使用memcache ,redis 之类的缓存，等累计到一定量再去更新数据库。或者mongodb 一类的nosql数据库，这里只是举例，就先不说这个。 横向分表 字面意思，就可以看出来，是把大的表结构，横向切割为同样结构的不同表，如，用户信息表，user\_1,user\_2等。表结构是完全一样，但是，根据某些特定的规则来划分的表，如根据用户ID来取模划分。 分表理由：根据数据量的规模来划分，保证单表的容量不会太大，从而来保证单表的查询等处理能力。

### 存储引擎对比





### 学号姓名课程成绩计算总分后倒序排序，找出各科及格的学号姓名

### 事务隔离级别

1. 读未提交 （脏读）
2. 读提交  （不可重复读）
3. 可重复读
4. 串行

MySQL原理（事务隔离级别、mvcc机制原理、B+树（每个节点一般存一页4K数据，4K是因为一次加载数据入内存，局部性原理，性能高，从而决定了一张表最大只能存多少数据），推荐看极客时间的《 MySQL45讲》）、MySQL主从同步原理及详细过程、MySQL两阶段提交，写入数据详细过程，事务详细过程、binlog、redolog、undolog分别作用；

### limit 优化

\#\#where

## **GMP调度**

### **调度算法**

当一个Goroutine创建被创建时，Goroutine对象被压入Processor的本地队列或者Go运行时 全局Goroutine队列。Processor唤醒一个Machine，如果Machine的waiting队列没有等待被 唤醒的Machine，则创建一个（只要不超过Machine的最大值，10000），Processor获取到Machine后，与此Machine绑定，并执行此Goroutine。Machine执行过程中，随时会发生上下文切换。当发生上下文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go调度器中Machine的栈保存在Goroutine对象上，只需要将Machine所需要的寄存器\(堆栈指针、程序计数器等\)保存到Goroutine对象上即可。如果此时Goroutine任务还没有执行完，Machine可以将Goroutine重新压入Processor的队列，等待下一次被调度执行。 如果执行过程遇到阻塞并阻塞超时（调度器检测这种超时），Machine会与Processor分离，并等待阻塞结束。此时Processor可以继续唤醒Machine执行其它的Goroutine，当阻塞结束时，Machine会尝试”偷取”一个Processor，如果失败，这个Goroutine会被加入到全局队列中，然后Machine将自己转入Waiting队列，等待被再次唤醒。

在各个Processor运行完本地队列的任务时，会从全局队列中获取任务，调度器也会定期检查全局队列，否则在并发较高的情况下，全局队列的Goroutine会因为得不到调度而”饿死”。如果全局队列也为空的时候，会去分担其它Processor的任务，一次分一半任务，比如，ProcessorA任务完成了，ProcessorB还有10个任务待运行，Processor在获取任务的时候，会一次性拿走5个。（是不是觉得Processor相互之间很友爱啊 \_）。

### goroutine切换条件 <a id="goroutine&#x5207;&#x6362;&#x6761;&#x4EF6;"></a>

在正常情况下，scheduler（调度器）会按照上面的流程进行调度，当一个G（goroutine）的时间片结束后将P（Processor）分配给下一个G，但是线程会发生阻塞等情况，看一下goroutine对线程阻塞等的处理。  


## Redis

### Redis底层数据结构

1. 字符串
2. List 列表
3. Hash 字典
4. Set集合
5. Sorted Set 有序集合

### 跳表原理

**12、什么是乐观锁和悲观锁**

1）乐观锁：就像它的名字一样，对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争不总是会发生，因此它不需要持有锁，将**比较-替换**这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。

2）悲观锁：还是像它的名字一样，对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像synchronized，不管三七二十一，直接上了锁就操作资源了。

### aof、RDB详细过程及线上怎么配置（一般AOF+RDB，此时原理是什么也要知道）

### 主从详细过程

### 分布式方案（TWproxy\codis）等原理（推荐看 黄建宏写的redis书）

### lru算法实现

## 

### Hash碰撞

哈希（Hash）算法，即散列函数。它是一种单向密码体制，即它是一个从明文到密文的不可逆的映射。哈希函数可以将任意长度的输入经过变化以后得到固定长度的输出。哈希函数的这种单向特征和输出数据长度固定的特征使得它可以生成消息或者数据。

### Hash算法用途

1.数据校验

2.唯一标识

3.哈希表

4.负载均衡

{% embed url="https://5.分布式存储" %}

### 避免Hash碰撞策略

#### 1.开放地址法\(再散列法\)

开放地执法有一个公式:Hi=\(H\(key\)+di\) MOD m i=1,2,…,k\(k&lt;=m-1\) 其中，m为哈希表的表长。di 是产生冲突的时候的增量序列。如果di值可能为1,2,3,…m-1，称线性探测再散列。如果di取1，则每次冲突之后，向后移动1个位置.如果di取值可能为1,-1,2,-2,4,-4,9,-9,16,-16,…kk,-kk\(k&lt;=m/2\)，称二次探测再散列。如果di取值可能为伪随机数列。称伪随机探测再散列。

#### 2.再哈希法Rehash

当发生冲突时，使用第二个、第三个、哈希函数计算地址，直到无冲突时。缺点：计算时间增加。比如上面第一次按照姓首字母进行哈希，如果产生冲突可以按照姓字母首字母第二位进行哈希，再冲突，第三位，直到不冲突为止.这种方法不易产生聚集，但增加了计算时间。

#### 3.链地址法（拉链法）

将所有关键字为同义词的记录存储在同一线性链表中.基本思想:将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。对比JDK 1.7 hashMap的存储结构是不是很好理解。至于1.8之后链表长度大于6rehash 为树形结构不在此处讨论。

#### 拉链法的优缺点

#### 优点：

①拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短；②由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况；③开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间；④在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。而对开放地址法构造的散列表，删除结点不能简单地将被删结 点的空间置为空，否则将截断在它之后填人散列表的同义词结点的查找路径。这是因为各种开放地址法中，空地址单元\(即开放地址\)都是查找失败的条件。因此在 用开放地址法处理冲突的散列表上执行删除操作，只能在被删结点上做删除标记，而不能真正删除结点。

#### 缺点：

指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度。

#### 4.建立一个公共溢出区

假设哈希函数的值域为\[0,m-1\],则设向量HashTable\[0..m-1\]为基本表，另外设立存储空间向量OverTable\[0..v\]用以存储发生冲突的记录。

## Http Tcp

### 网页从输入链接到返回页面经历了什么？

简单说说，浏览器根据请求的url交给dns域名解析，查找真正的ip地址，向服务器发起请求；服务器交给后台处理后，返回数据，浏览器会接收到文件数据，比如，html,js，css，图像等；然后浏览器会对加载到的资源进行语法解析，建立相应的内部数据结构；载入解析到得资源文件，渲染页面，完成显示页面效果。

### 三次握手四次挥手

> 第一次挥手

主动关闭的一方，发送一个FIN\(上述讲过---当FIN=1，表示此报文段是一个释放连接的请求报文\)，传送数据，用来告诉对方（被动关闭方），说不会再给你发送数据了。---主动关闭的一方可以接受数据。

> 第二次挥手

被动关闭方 收到 FIN 包，发送 ACK 给对方，确认序号。

> 第三次挥手

被动关闭方 发送一个 FIN，关闭方，说我不会再给你发数据了。（你不给我发送数据，我也不给你发送数据了）

> 第四次挥手

主动关闭一方收到 FIN ，发送要给 ACK ，用来确认序号

###  TCP：滑动窗口

### 快重传

### 慢启动（二进制退避算法）

### 分包、拆包问题

### MAC头、IP头、tcp头

### http的keepalive--http1.1默认开启了keepalive

### https握手过程

### http2原理

### DNS原理

### CDN原理 

### http状态码含义，出现4XX，5XX如何定位问题）

### http头包含哪些东西

### http的chunk模式是啥

当客户端向服务器请求一个静态页面或者一张图片时，服务器可以很清楚的知道内容大小，然后通过Content-Length消息首部字段告诉客户端需要接收多少数据。但是如果是动态页面等时，服务器是不可能预先知道内容大小，这时就可以使用Transfer-Encoding：chunk模式来传输数据了。即如果要一边产生数据，一边发给客户端，服务器就需要使用"Transfer-Encoding: chunked"这样的方式来代替Content-Length。

在进行chunked编码传输时，在回复消息的头部有Transfer-Encoding: chunked

编码使用若干个chunk组成，由一个标明长度为0的chunk结束。每个chunk有两部分组成，第一部分是该chunk的长度，第二部分就是指定长度的内容，每个部分用CRLF隔开。在最后一个长度为0的chunk中的内容是称为footer的内容，是一些没有写的头部内容。



## IO多路复用

### poll / epoll

I/O多路复用这个概念被提出来以后， select是第一个实现 \(1983 左右在BSD里面实现的\)。select 被实现以后，很快就暴露出了很多问题。

* select 会修改传入的参数数组，这个对于一个需要调用很多次的函数，是非常不友好的。 
*  select 如果任何一个sock\(I/O stream\)出现了数据，select 仅仅会返回，但是并不会告诉你是那个sock上有数据，于是你只能自己一个一个的找，10几个sock可能还好，要是几万的sock每次都找一遍，这个无谓的开销就颇有海天盛筵的豪气了。 
* select 只能监视1024个链接， 这个跟草榴没啥关系哦，linux 定义在头文件中的，参见_FD\_SETSIZE。_
* select 不是线程安全的，如果你把一个sock加入到select, 然后突然另外一个线程发现，尼玛，这个sock不用，要收回。对不起，这个select 不支持的，如果你丧心病狂的竟然关掉这个sock, select的标准行为是。。呃。。不可预测的， 这个可是写在文档中的哦.

 “If a file descriptor being monitored by select\(\) is closed in another thread, the result is unspecified”  
 霸不霸气于是14年以后\(1997年）一帮人又实现了poll, poll 修复了select的很多问题，比如

* poll 去掉了1024个链接的限制，于是要多少链接呢， 主人你开心就好。 
*  poll 从设计上来说，不再修改传入数组，不过这个要看你的平台了，所以行走江湖，还是小心为妙。

**其实拖14年那么久也不是效率问题， 而是那个时代的硬件实在太弱，一台服务器处理1千多个链接简直就是神一样的存在了，select很长段时间已经满足需求。**

但是poll仍然不是线程安全的， 这就意味着，不管服务器有多强悍，你也只能在一个线程里面处理一组I/O流。你当然可以那多进程来配合了，不过然后你就有了多进程的各种问题。

于是5年以后, 在2002, 大神 Davide Libenzi 实现了epoll.epoll 可以说是I/O 多路复用最新的一个实现，epoll 修复了poll 和select绝大部分问题, 比如：

* epoll 现在是线程安全的。 
* epoll 现在不仅告诉你sock组里面数据，还会告诉你具体哪个sock有数据，你不用自己去找了。

### 线程与进程区别

### Hash表实现原理与冲突解决

## Nginx 

nginx高性能原因（IO多路复用技术 epoll原理与使用到的数据结构），senfile快的原因、文件事件、时间事件概念、nginx进程如何管理（master/worker分别干嘛的，惊群问题如何处理，进程管理的信号、数据同步的信号量两者区别）、平滑重启原理（go如何做）、平滑升级、平滑重启如何做、nginx11阶段是、keepalive及对应配置含义（应用很广泛，可能会问）、负载均衡有哪些方式及对应算法、限流算法、openresty原理及应用、nginx连接池；

## rabbitmq

### 作用：削峰，异步，解耦

消息 =&gt; 交换机 =&gt; 通过绑定的`key` =&gt; 队列 =&gt; 消费者

## 面向对象

**面向对象**的**三大**特性是"封装、"多态"、"继承"，五大原则是"单一职责原则"、"开放封闭原则"、"里氏替换原则"、"依赖倒置原则"、"接口分离原则"、"迪米特原则（高内聚低耦合）"。

### 微服务

其中软件由通过明确定义的 API 进行通信的小型独立服务组成。这些服务由各个小型独立团队负责。



### 微服务的特点

1. 单一职责 每个微服务都需要满足单一职责原则，微服务本身是内聚的，因此微服务通常比较小。比如示例中每个微服务按业务逻辑划分，每个微服务仅负责自己归属于自己业务领域的功能。
2. 自治 一个微服务就是一个独立的实体，它可以独立部署、升级，服务与服务之间通过REST等形式的标准接口进行通信，并且一个微服务实例可以被替换成另一种实现，而对其它的微服务不产生影响。
3. 简化部署 在一个单块系统中，只要修改了一行代码，就需要对整个系统进行重新的构建、测试，然后将整个系统进行部署。而微服务则可以对一个微服务进行部署。
4. 可扩展 应对系统业务增长的方法通常采用横向（Scale out）或纵向（Scale up）的方向进行扩展。分布式系统中通常要采用Scale out的方式进行扩展。因为不同的功能会面对不同的负荷变化，因此采用微服务的系统相对单块系统具备更好的可扩展性。
5. 灵活组合 在微服务架构中，可以通过组合已有的微服务以达到功能重用的目的。
6. 技术异构 在一个大型系统中，不同的功能具有不同的特点，并且不同的团队可能具备不同的技术能力。因为微服务间松耦合，不同的微服务可以选择不同的技术栈进行开发。 同时，在应用新技术时，可以仅针对一个微服务进行快速改造，而不会影响系统中的其它微服务，有利于系统的演进。
7. 高可靠 微服务间独立部署，一个微服务的异常不会导致其它微服务同时异常。通过隔离、融断等技术可以避免极大的提升微服务的可靠性。
8. 基础设施自动化
9. 服务组件化
10. 容错设计
11. 演进式设计

#### 微服务的缺点

1. 复杂度高 微服务间通过REST、RPC等形式交互，相对于Monolithic模式下的API形式，需要考虑被调用方故障、过载、消息丢失等各种异常情况，代码逻辑更加复杂。 对于微服务间的事务性操作，因为不同的微服务采用了不同的数据库，将无法利用数据库本身的事务机制保证一致性，需要引入二阶段提交等技术。 同时，在微服务间存在少部分共用功能但又无法提取成微服务时，各个微服务对于这部分功能通常需要重复开发，或至少要做代码复制，以避免微服务间的耦合，增加了开发成本。
2. 运维复杂 在采用微服务架构时，系统由多个独立运行的微服务构成，需要一个设计良好的监控系统对各个微服务的运行状态进行监控。运维人员需要对系统有细致的了解才对够更好的运维系统。
3. 影响性能 微服务的间通过REST、RPC等形式进行交互，通信的时延会受到较大的影响。

内存分析工具 内存溢出 火焰图 

### map里可以key 类型限制，value无类型限制

golang中的map，的 key 可以是很多种类型，比如 bool, 数字，string, 指针, channel , 还有 只包含前面几个类型的 interface types, structs, arrays 

显然，slice， map 还有 function 是不可以了，因为这几个没法用 == 来判断

### GMP模型 goroutine存在哪里 

### php map不是无序的，go map为什么无序 

它生成了随机数。用于决定从哪里开始循环迭代。更具体的话就是根据随机数，选择一个桶位置作为起始点进行遍历迭代

因此每次重新 `for range map`，你见到的结果都是不一样的。那是因为它的起始位置根本就不固定！

* 从已选定的桶中开始进行遍历，寻找桶中的下一个元素进行处理
* 如果桶已经遍历完，则对溢出桶 `overflow buckets` 进行遍历处理
* [https://cloud.tencent.com/developer/article/1422355](https://cloud.tencent.com/developer/article/1422355)

###  mongodb groupby 

### MVCC 隔离机制的原理

###  mq队列如何保证都push了

①：可以选择使用rabbitmq提供是事物功能，就是生产者在发送数据之前开启事物，然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会受到异常报错，这时就可以回滚事物，然后尝试重新发送；如果收到了消息，那么就可以提交事物。

```text
  channel.txSelect();//开启事物
  try{
      //发送消息
  }catch(Exection e){
      channel.txRollback()；//回滚事物
      //重新提交
  }
复制代码
```

**缺点：** rabbitmq事物已开启，就会变为同步阻塞操作，生产者会阻塞等待是否发送成功，太耗性能会造成吞吐量的下降。

②：可以开启confirm模式。在生产者哪里设置开启了confirm模式之后，每次写的消息都会分配一个唯一的id，然后如何写入了rabbitmq之中，rabbitmq会给你回传一个ack消息，告诉你这个消息发送OK了；  
作者：一条路上的咸鱼  
链接：https://juejin.cn/post/6844903849099018253  
来源：掘金  
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

### mysql 主从同步

### 并发写入

将评论直接推送到 rabbitMq之类的消息中间件，然后再开多进程进行消费插入mysql\(开几个根据服务器性能\)，这样负载就是可控的了

监控主从延迟的方法有多种：

1. Slave 使用本机当前时间，跟 Master 上 binlog 的时间戳比较
2. `pt-heartbeat`、`mt-heartbeat`

**本质**：同一条 SQL，`Master` 上`执行结束`的时间 vs. `Slave` 上`执行结束`的时间。

原因

* Master 上，`大事务`，耗时长：优化业务，拆分为小事务
  * Master 上，SQL 执行速度慢：优化索引，提升索引区分度（事务内部有查询操作）
  * Master 上，批量 DML 操作：建议延迟至业务低峰期操作
* Master 上，`多线程写入频繁`， Slave 单线程速度跟不上：提升 Slave 硬件性能、借助中间件，改善主从复制的单线程模式

### mysql锁  **InnoDB加锁方法：**

* 意向锁是 InnoDB 自动加的， 不需用户干预。
* 对于 UPDATE、 DELETE 和 INSERT 语句， InnoDB 会自动给涉及数据集加排他锁（X\)；
* 对于普通 SELECT 语句，InnoDB 不会加任何锁； 事务可以通过以下语句显式给记录集加共享锁或排他锁：
  * 共享锁（S）：SELECT \* FROM table\_name WHERE ... LOCK IN SHARE MODE。 其他 session 仍然可以查询记录，并也可以对该记录加 share mode 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。
  * 排他锁（X\)：SELECT \* FROM table\_name WHERE ... FOR UPDATE。其他 session 可以查询该记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁
* **隐式锁定：**

InnoDB在事务执行过程中，使用两阶段锁协议：

随时都可以执行锁定，InnoDB会根据隔离级别在需要的时候自动加锁；

锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在**同一时刻**被释放。

### rabbitmq过程

{% embed url="https://1.声明MessageQueue" %}

a\)消费者是无法订阅或者获取不存在的MessageQueue中信息。

b\)消息被Exchange接受以后，如果没有匹配的Queue，则会被丢弃。  
a\) Exclusive：排他队列，如果一个队列被声明为排他队列，该队列仅对首次声明它的连接可见，并在连接断开时自动删除。这里需要注意三点：其一，排他队列是基于连接可见的，同一连接的不同信道是可以同时访问同一个连接创建的排他队列的。其二，“首次”，如果一个连接已经声明了一个排他队列，其他连接是不允许建立同名的排他队列的，这个与普通队列不同。其三，即使该队列是持久化的，一旦连接关闭或者客户端退出，该排他队列都会被自动删除的。这种队列适用于只限于一个客户端发送读取消息的应用场景。

b\) Auto-delete:自动删除，如果该队列没有任何订阅的消费者的话，该队列会被自动删除。这种队列适用于临时队列。

c\) Durable:持久化，这个会在后面作为专门一个章节讨论。

d\) 其他选项，例如如果用户仅仅想查询某一个队列是否已存在，如果不存在，不想建立该队列，仍然可以调用queue.declare，只不过需要将参数passive设为true，传给queue.declare，如果该队列已存在，则会返回true；如果不存在，则会返回Error，但是不会创建新的队列。

{% embed url="https://2.生产者发送消息" %}

a\) 如果是Direct类型，则会将消息中的RoutingKey与该Exchange关联的所有Binding中的BindingKey进行比较，如果相等，则发送到该Binding对应的Queue中。

如果是 Fanout 类型，则会将消息发送给所有与该 Exchange 定义过 Binding 的所有 Queues 中去，其实是一种广播行为。

\)如果是Topic类型，则会按照正则表达式，对RoutingKey与BindingKey进行匹配，如果匹配成功，则发送到对应的Queue中。

3 . 消费者订阅消息  
在RabbitMQ中消费者有2种方式获取队列中的消息:

a\) 一种是通过basic.consume命令，订阅某一个队列中的消息,channel会自动在处理完上一条消息之后，接收下一条消息。（同一个channel消息处理是串行的）。除非关闭channel或者取消订阅，否则客户端将会一直接收队列的消息。

b\) 另外一种方式是通过basic.get命令主动获取队列中的消息，但是绝对不可以通过循环调用basic.get来代替basic.consume，这是因为basic.get RabbitMQ在实际执行的时候，是首先consume某一个队列，然后检索第一条消息，然后再取消订阅。如果是高吞吐率的消费者，最好还是建议使用basic.consume。

4 . 持久化： Rabbit MQ默认是不持久队列、Exchange、Binding以及队列中的消息的，这意味着一旦消息服务器重启，所有已声明的队列，Exchange，Binding以及队列中的消息都会丢失。通过设置Exchange和MessageQueue的durable属性为true，可以使得队列和Exchange持久化，但是这还不能使得队列中的消息持久化，这需要生产者在发送消息的时候，



![](../.gitbook/assets/image%20%2837%29.png)

1. 介绍自己做过的项目，突出难点解决方案
2. 业务配置如何热更新，不重启服务
3. kafka比mq用的多，需要看，mq的模式fanout和direct区别，业务用的哪个
4. Lru是不是自己实现的（去年字节直接让手撸Lru），Lru如果有多个实例怎么配置？（之前的业务场景只用了一个）
5. redis集群：主从，哨兵模式
6. 开源error包和errors.New的区别

### 微服务相关，自己封的rpc使用什么协议？http？thrift？grpc？

基于TCP 的 RPC 工作过程

1. 客户端对请求的对象序列化
2. 客户端连接服务端，并将序列化的对象通过socket 传输给服务端，并等待接收服务端的响应
3. 服务端收到请求对象后将其反序列化还原客户端的对象
4. 服务端从请求对象中获取到请求的参数，然后执行对应的方法，得到返回结果
5. 服务端将其结果序列化并传给客户端，客户端得到响应结果对象后将其反序列化，得到响应结果
6. IO多路复用：select poll epoll
7. 网校的开源go-zero框架，我没参与。。。
8. context用法
9. 内存分配（想问没问，悄悄说了一句）
10. sync和atomic，sync.pull

## 实际问题

### 数据大了分表分库

### 设计一个类似微博、微信、12306等等系统

### 边界考虑充分

### 双活建设、宏观架构

### 遇到问题的解决思路如500、499、502、504，服务治理理念等等；

## 系统：

### 内存分段分页原理、

### 协程、线程、进程概念、进程状态（结合状态问为什么出现，如僵尸进程）、

### go的协程原理、软中断硬中断概念、上下文切换概念、cpu负载概念等等、linux命名常用的柑橘够了，如分析nginx请求日志的访问top10的IP或URL;



## Gin框架 

### Static静态文件配置



### ToLearn

spark实现实时统计指标

循环队列，622 

解决问题的方法论

反转链表

3sum

linux io模型，协程是什么，redis cmd， mysql 

实现LRU

meeting room 252

求x的n次方（二分 递归）













