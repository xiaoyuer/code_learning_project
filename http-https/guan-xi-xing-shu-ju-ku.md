# 关系型数据库

{% embed url="http://www.yinwang.org/blog-cn/2014/04/24/relational" %}

先从存储说起。王垠的文章中提到了struct会比关系型灵活的多。struct里可以有指针任意的指、可以任意嵌套。而关系型说白了就是一个大数组。问题是，struct的强大能力只有在可以很容易随机访问的内存里才能实现，而数据库一开始就要处理数据量远超内存的场景。数据库必须解决外存（早期主要是硬盘）的问题。硬盘因为要物理旋转，需要按照“簇”的方式访问，所以像struct那种指来指去的方法到了外存上基本上就会把性能表现降低数个数量级。上过计算机课的人都知道有些数据结构和算法适合内存，而有些适合外存（比如BTree）。关系型数据库最终选择了BTree。这就要求整个数据的结构必须大致得是“一行行”的，放在树的节点；树的结构本身用来做查询的优化。

因为整个数据的存储形式形成了BTree，整个查询的优化就可以围绕BTree来做。假如用struct，因为是任意的，所以就无法做优化。只有开发人员自己才知道数据结构，才知道怎么使用。比如丢给你个指针做入口，查找某个可能触达的数据，不知道内部结构的情况下，能做的也就是深度优先和广度优先去扫。

有些数据结构可以帮忙，比如常用的hash，list，stack，skiplist……。开发者可以用它们来优化自己的查询。就算是外存的相关逻辑，也可以抽象出来，用某种lib来做。问题是，这么做对于稍微复杂一点的场景，就会**无比的麻烦，以至于在工程上不可行**。你能体会到一个业务程序员在思考者各种折扣和返券的时候，还得考虑哪个数据存内存，哪个存到磁盘的哪个簇，然后再做查询优化的心情吗？这里还没提隔离的问题、原子性的问题、锁的问题、磁盘刷盘的问题……。没有靠谱数据库的支持，根本就无法在合理的时间deliver可用的代码，程序员需要同时花大精力和机器与PM双线作战。并不是每个人都是计算机科学的编码高手，熟悉算法、数据结构和存储，以及业务逻辑，都能在两边游刃有余。并不是每家公司都能雇佣多个像王垠这样的做编译的高级工程师写数据库的访问程序。

出现一个靠谱的、通用的数据库的前提必然是数据访问提供一个抽象和一套接口。而这个接口从使用者的角度，必然**围绕着数据增删改查来做的**，绝对不可能暴露底层的实现细节（比如对MyISAM表插入一条记录会加个表锁，而对InnoDB插就是另外一套基于MVCC的逻辑）。也许SQL并不一定是个完美的接口，但是是经过多少年的用户和数据库厂商磨合的结果。这个结果甚至逼迫着得很多现代非关系型数据库、分布式数据库必须提供类似于SQL的部分语法支持。有了SQL和关系型数据库，大量不那么熟悉数据结构、查询优化、存储的开发者可以加入到开发的队伍中，构建起大量的信息系统。整个产业就在这个过程中极大的发展。

在整个行业发展过程中，一些需求催生了各种各样的的优化的机会。有人抓住机会去提出新的数据模型和查询接口。比如：

* 想内存数据库，上redis
* 想高性能访问KV模型，有rocksDB
* 想制作树状结构的数据，mongo你值得拥有
* 想做图分析，有图数据库
* 想要时序数据，有influxdb和Prometheus这种列存
* 想做Data Warehouse，有GP、有大规模的并行计算引擎
* 想做高性能海量数据存储，但是访问的方式相对简单，可以上Hadoop全家桶，Spark全家桶
* 想做海量数据的KV，有HBase，Cassandra
* ……

就连SQL自己也在演进，比如各大数据库增加了对json格式的支持，MySQL还搞了个X-API，弄得像mongo一样；Postgres中一列可以是复合的类型（类似于struct），也可以是数组类型。mysql和postgres还支持全文索引（按照王垠的讲法，是不是这时候得先用一套LSM tree库玩转sstable管理，然后再攒一个lucene做分词和倒排？）

根据实际需求，从上面这些备选中，总能找到几个东西组合在一起满足需要。如果还不够用，那就按照需求定制，就像polarDB，TiDB。但我相信，绝大部分的开发场景，弄个mysql，sqlite之类的就完事了，不需要特别仔细的优化。

